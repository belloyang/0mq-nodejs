#include "IMiniSEEDRecordsSynthesizer.h"

#include <cstring>

IMiniSEEDRecordsSynthesizer::IMiniSEEDRecordsSynthesizer(const std::shared_ptr<buffer_base<SteimFrame_t>>& framesBuffer,
  const std::shared_ptr<IMiniSEEDRecordsSynthesizerDelegate>& delegate,
  const bool useBigEndian,
  const std::shared_ptr<ILogger>& logger)
  : m_framesBuffer(framesBuffer)
  , m_delegate(delegate)
  , m_bUseBigEndian(useBigEndian)
  , m_logger(logger)
{
  __DEV_CALLSTACK_FUNC__;
  this->reset(0);
}

void IMiniSEEDRecordsSynthesizer::reset(const sample_t lastSample)
{
  __DEV_CALLSTACK_FUNC__;
  ::memset(&m_packet, 0, sizeof(m_packet));
  m_packet.emptyDatasets = steim::DATASETS_PER_FRAME - 3;
  //add initial sample to start calculation differences based on it (simulated continuing steim stream)
  m_packet.samples[0] = lastSample;
  //discard the record (!discards first sample set flag in particular)
  ::memset(&m_record, 0, sizeof(m_record));
}

void IMiniSEEDRecordsSynthesizer::addSample(const sample_t sample)
{
  __DEV_CALLSTACK_FUNC__;
  __ASSERT__(m_framesBuffer != nullptr && m_framesBuffer->count() > 0 && "frames buffer is not set!");
  // normalize sample
  const sample_t normalizedSample = this->_normalizeSampleImpl(sample);
  // save the very first sample
  if (!m_record.isFirstSampleSet)
  {
    m_record.firstSample = normalizedSample;
    m_record.isFirstSampleSet = true;
  }
  // process sample
  this->_processSampleImpl(normalizedSample);
}

void IMiniSEEDRecordsSynthesizer::flush()
{
  __DEV_CALLSTACK_FUNC__;
  this->_flushImpl();
}

sample_t IMiniSEEDRecordsSynthesizer::normalizeSample(const sample_t sample) const
{
  __DEV_CALLSTACK_FUNC__;
  return this->_normalizeSampleImpl(sample);
}

void IMiniSEEDRecordsSynthesizer::_finishDataset(const uint32_t compression, const uint8_t samplesInDataset, const uint32_t dataset,
  const uint32_t nSamplesRemain, SteimFrame_t& output, const bool bForceRecordFinish)
{
  __DEV_CALLSTACK_FUNC__;
  //tss_harv::increase amount of samples in the packet
  m_packet.numberSamples += samplesInDataset;
  m_record.nSamples += samplesInDataset;
  const uint32_t lastSampleIndex = (m_packet.currentSampleIndex + NUM_ELEMENTS(m_packet.samples) - nSamplesRemain) % NUM_ELEMENTS(m_packet.samples);
  m_record.lastSample = m_packet.samples[lastSampleIndex];
  //tss_harv::dump dataset
  {
    const uint8_t datasetIndex = steim::DATASETS_PER_FRAME - m_packet.emptyDatasets;
    output[datasetIndex] = dataset;
  }

  //tss_harv::decrease amount of empty dataset as we're adding new one
  const int emptyDatasets = m_packet.emptyDatasets - 1;
  //tss_harv::update compression frame (writing dataset compression 2bits nibble to "compression frame")
  m_packet.compression |= compression << (2 * emptyDatasets);
  // update amount of empty datasets in packet (effectively decrease it by 1)
  m_packet.emptyDatasets = emptyDatasets;
  //tss_harv::check if no more datasets can be compressed within packet or finish record requested
  if (bForceRecordFinish || emptyDatasets <= 0)
  {
    this->_finishFrame(nSamplesRemain, bForceRecordFinish);
  }
  //tss_harv::discard Steim state (as new frame will be generated)
  m_packet.state_steim.bitness = 0;
  m_packet.state_steim.count = 0;
}

void IMiniSEEDRecordsSynthesizer::_finishFrame(const uint32_t nSamplesRemain, const bool bForceRecordFinish)
{
  __DEV_CALLSTACK_FUNC__;
  const uint32_t currentFrameIdx = m_record.currentFrame;
  steim::SteimFrameData* frames = m_framesBuffer->ptr<steim::SteimFrameData>();

  //tss_harv::save compression
  frames[currentFrameIdx].datasets1.compression = m_bUseBigEndian ? endianness_utils::swap(m_packet.compression) : m_packet.compression;

  // clear the tail (empty datasets in the current frame)
  {
    const uint32_t nEmptyDatasets = m_packet.emptyDatasets;
    const uint32_t filledDatasets = steim::DATASETS_PER_FRAME - nEmptyDatasets;
    steim::SteimFrameData& currentFrame = frames[currentFrameIdx];
    ::memset(&currentFrame.frame[filledDatasets], 0, nEmptyDatasets * sizeof(uint32_t));
  }

  //tss_harv::if frames buffer is filled up -> finish the entire record
  if (bForceRecordFinish || currentFrameIdx >= m_framesBuffer->count() - 1)
  {
    //tss_harv::set first and last samples for iteration (1st and 2nd datasets in 0th record)
    frames[0].datasets1.first_sample = m_bUseBigEndian ? endianness_utils::swap(m_record.firstSample) : m_record.firstSample;
    frames[0].datasets1.last_sample = m_bUseBigEndian ? endianness_utils::swap(m_record.lastSample) : m_record.lastSample;
    //tss_harv::finish record
    this->_finishRecord(nSamplesRemain);
  }
  else //update frame iterators (record continues to the next frame with 15 datasets for data in it)
  {
    m_record.currentFrame++;
    m_packet.emptyDatasets = steim::DATASETS_PER_FRAME - 1; //15 datasets remain for data (16 - 1 for compression)
  }

  //tss_harv::discard compression
  m_packet.compression = 0;
}

void IMiniSEEDRecordsSynthesizer::_finishRecord(const uint32_t nSamplesRemain)
{
  __DEV_CALLSTACK_FUNC__;
  // clear the tail (remaining Steim frames in the record)
  {
    SteimFrame_t* const framesPtr = m_framesBuffer->ptr();
    const uint32_t currentFrameIdx = m_record.currentFrame;
    const uint32_t nFramesTotal = m_framesBuffer->count();
    const uint32_t nFramesRemain = nFramesTotal - currentFrameIdx - 1u;
    ::memset(&framesPtr[currentFrameIdx + 1], 0, nFramesRemain * sizeof(SteimFrame_t));
  }

  //tss_harv::commit record
  this->_commitRecordImpl();
  //tss_harv::discard record iterators
  {
    //tss_harv::there are some samples (nSamplesRemain) that are not included into the packet as it finished before them
    //synthesizer is built the way it's always at least 1 sample remain unless forcible record flushing is done at some stage.
    //tss_harv::update the first sample for the next record (it is the first sample in samples that remain/not included in the previous packet)
    if (nSamplesRemain > 0)
    {
      const uint32_t firstSampleIndex = (m_packet.currentSampleIndex + NUM_ELEMENTS(m_packet.samples) - nSamplesRemain + 1) % NUM_ELEMENTS(m_packet.samples);
      m_record.firstSample = m_packet.samples[firstSampleIndex];
    }
    else //0 samples remains -> set flag that first sample is not set (will be set on the next addSample)
    {
      m_record.isFirstSampleSet = false;
    }
    m_record.lastSample = 0; //we do not care about it as it gets updated before flushing the packet, just zerify it for clarify
    m_record.nSamples = 0;
    m_record.currentFrame = 0;
  }

  //tss_harv::reset datasets iterators (the next frame is going to be the very first in the next record)
  {
    m_packet.emptyDatasets = steim::DATASETS_PER_FRAME - 3; //13 dataset remain (16 - 3 held by meta info)
  }
}
