#define NOMINMAX

#include "GraphBuilder.h"

#include "Generators/PDBLogsGenerator.h"
#include "Generators/SensorInputGenerator.h"
#include "Generators/HealthInputGenerator.h"
#include "Generators/ClockStatusGenerator.h"
#include "Writers/TxtLogWriterFilter.h"
#include "Writers/PSFWriterFilter.h"
#include "Writers/MiniSEEDWriterFilter_SensorInput.h"
#include "Writers/MiniSEEDWriterFilter_SohData.h"
#include "Writers/MiniSEEDWriterFilter_ClockStatus.h"
#include "Readers/PSFReaderFilter.h"
#include "Progress/ProgressFilter.h"
#include "Processors/ProcessorDelegateFilter.h"

#include "mem_pool.h"

#include <Logger/loggers.h>
#include <PlatformUtils/PlatformUtils.h>
#include <Utils/psf_utils.h>

#include <DataTypes/pdb_data_types.h>

#include <limits>

GraphBuilder::GraphBuilder(const std::shared_ptr<ILogger>& logger)
: m_logger(logger)
{
  __DEV_CALLSTACK_FUNC__;
}

bool GraphBuilder::_makePath(const std::string& path) const
{
  __DEV_CALLSTACK_FUNC__;
  const std::string resolvedPath = PlatformUtils::getInstance()->resolvePath(path);
  if (!PlatformUtils::getInstance()->makePath(resolvedPath))
  {
    m_logger->error(__THIS_FUNC__, eErrorCategory::ERROR_CATEGORY_LIBRARY, eHarvLibErrorCode::HARVLIB_ERROR_OPERATION_FAILED,
      "Failed to create path '%s'", 
      resolvedPath.c_str());
    return false;
  }

  return true;
}

IBaseFilter* GraphBuilder::_makeChain(IBaseFilter* filter0, ...) const
{
  __DEV_CALLSTACK_FUNC__;
  if (filter0 == nullptr)
    return nullptr;

  va_list vl;
  va_start(vl, filter0);
  IBaseFilter* prevFilter = filter0;
  while (true)
  {
    IBaseFilter* filter = va_arg(vl, IBaseFilter*);
    if (filter == nullptr)
      break;

    prevFilter->setSuccessor(std::shared_ptr<IBaseFilter>(filter));
    prevFilter = filter;
  }
  va_end(vl);
  return filter0;
}

IBaseFilter* GraphBuilder::_makeChain(const std::vector<IBaseFilter*>& filters) const
{
  __DEV_CALLSTACK_FUNC__;
  if (filters.empty())
    return nullptr;
  
  //tss_harvlib::set successors
  IBaseFilter* prevFilter = nullptr;
  for (const auto& filter : filters)
  {
    if (prevFilter != nullptr)
      prevFilter->setSuccessor(std::shared_ptr<IBaseFilter>(filter));

    prevFilter = filter;
  }
  
  return filters.at(0);
}


//----------------------------<Forensic logs>----------------------------
std::shared_ptr<IBaseFilter> GraphBuilder::buildLogsGenerationChain(const std::shared_ptr<PSFLibrary>& library, 
  const timestamp_t startTimestamp, const uint32_t nLogs) const
{
  __DEV_CALLSTACK_FUNC__;
  //tss_harv::restore volume from library
  std::shared_ptr<PSFVolume> const volume(library->findVolumeByID(PDB_eVolumeID::VOLUME_FORENSIC_LOG));
  if (volume == nullptr)
  {
    m_logger->error(__THIS_FUNC__, eErrorCategory::ERROR_CATEGORY_LIBRARY, eHarvLibErrorCode::HARVLIB_ERROR_VOLUME_NOT_FOUND, 
      "Failed to find VOLUME_FORENSIC_LOG(id=%u) volume in library", (uint32_t)PDB_eVolumeID::VOLUME_FORENSIC_LOG);
    return nullptr;
  }

  uint32_t nRecordsToGenerate = nLogs;
  //tss_harv:: n=-1 means fill up completely
  if (nLogs == (uint32_t)-1)
  {
    const sPSFVolumeHeader_t* const pHeader = volume->getHeader();
    const uint32_t nRecordsPerSection = psf_utils::get_data_elements_per_section_max<MsgForensicLog::Header>();
    //tss_harvlib::records per volume = (nSections - 1(for volumes' header)) * records per section
    nRecordsToGenerate = (pHeader->sizeInChapters - 1) * nRecordsPerSection;
    m_logger->info(__THIS_FUNC__, "%u logs will be generated to fill up the PSF volume entirely!", nRecordsToGenerate);
  }

  //tss_harv::creating chain
  IBaseFilter* const pRootFilter = this->_makeChain(
      new PDBLogsGenerator(startTimestamp, nRecordsToGenerate, 0.01f, m_logger), //Logs generator filter (notifies progress each 1%)
      new PSFWriterFilter(volume, m_logger), //PSF writer filter (dumps logs to PSF library)
      nullptr);
  return std::shared_ptr<IBaseFilter>(pRootFilter);
}

std::shared_ptr<IBaseFilter> GraphBuilder::buildLogsHaverstingChain(const IOperation* operation, 
  const std::shared_ptr<PSFLibrary>& library,
  const sHarvestParams& params,
  const uint32_t maxQueueSize,
  const std::shared_ptr<IClient>& client,
  const std::shared_ptr<IProgressDelegate>& progressDelegate) const
{
  __DEV_CALLSTACK_FUNC__;
  // restore volume from library
  std::shared_ptr<PSFVolume> const volume(library->findVolumeByID(PDB_eVolumeID::VOLUME_FORENSIC_LOG));
  if (volume == nullptr)
  {
    m_logger->error(__THIS_FUNC__, eErrorCategory::ERROR_CATEGORY_LIBRARY, eHarvLibErrorCode::HARVLIB_ERROR_VOLUME_NOT_FOUND, 
      "Failed to find VOLUME_FORENSIC_LOG(id=%u) volume in library", (uint32_t)PDB_eVolumeID::VOLUME_FORENSIC_LOG);
    return nullptr;
  }

  // create output path
  if (!this->_makePath(params.outputDir))
  {
    m_logger->error(__THIS_FUNC__, eErrorCategory::ERROR_CATEGORY_LIBRARY, eHarvLibErrorCode::HARVLIB_ERROR_OPERATION_FAILED,
      "Failed to create '%s' directory",
      params.outputDir.c_str());
    return nullptr;
  }

  std::vector<IBaseFilter*> filters;
  {
    //PSF reader filter (1 page preserved as MsgLog is designed to fit within 1 page)
    //2N + 1 - memory pool size for reader because consumer filter uses 2 N-sized queues (collecting queue + processing queue)
    const uint32_t nPagesPerLogRecord = psf_utils::get_data_element_size_in_pages<MsgForensicLog::Header>();
    filters.push_back(new PSFReaderFilter(volume, params,
                                          (maxQueueSize << 1) + 1, nPagesPerLogRecord, m_logger));
    if (!params.outputDir.empty())
    {
      //Txt log writer filter (dumps logs to txt file)
      filters.push_back(new TxtLogWriterFilter(library, params, maxQueueSize, m_logger));
    }
    else
    {
      m_logger->warning(__THIS_FUNC__, "Output directory was not specified! Log-file generation is DISABLED!");
    }
    //Progress filter
    filters.push_back(new ProgressFilter(operation, client, progressDelegate, m_logger));
  }
  IBaseFilter* const pRootFilter = this->_makeChain(filters);
  return std::shared_ptr<IBaseFilter>(pRootFilter);  
}


//----------------------------<Sensor input>----------------------------
std::shared_ptr<IBaseFilter> GraphBuilder::buildSensorInputGenerationChain(const std::shared_ptr<PSFLibrary>& library,
  const timestamp_t startTimestamp, const uint8_t channelsMask, const uint32_t nPackets,
  const PDB_eMediaType_t mediaType, const bool useBigEndian,
  const std::shared_ptr<IGapGenerator>& gapGenerator,
  const double signalLevel, const double noiseLevel) const
{
  __DEV_CALLSTACK_FUNC__;
  //tss_harv::restore volume from library
  std::shared_ptr<PSFVolume> const volume(library->findVolumeByID(PDB_eVolumeID::VOLUME_SENSOR_TIME_SERIES));
  if (volume == nullptr)
  {
    m_logger->error(__THIS_FUNC__, eErrorCategory::ERROR_CATEGORY_LIBRARY, eHarvLibErrorCode::HARVLIB_ERROR_VOLUME_NOT_FOUND,
      "Failed to find VOLUME_SENSOR_TIME_SERIES(id=%u) volume in library", (uint32_t)PDB_eVolumeID::VOLUME_SENSOR_TIME_SERIES);
    return nullptr;
  }

  uint32_t nRecordsToGenerate = nPackets;
  //tss_harv:: n=-1 means fill up completely
  if (nPackets == (uint32_t)-1)
  {
    const sPSFVolumeHeader_t* const pHeader = volume->getHeader();
    const uint32_t nRecordsPerSection = psf_utils::get_data_elements_per_section_max<MsgSensorInput::Header>();
    //tss_harvlib::records per volume = (nSections - 1(for volumes' header)) * records per section
    nRecordsToGenerate = (pHeader->sizeInChapters - 1) * nRecordsPerSection;
    m_logger->info(__THIS_FUNC__, "%u packets for channels mask %c%c%c%c%c%c%c%c will be generated to fill up the PSF volume entirely!",
      nRecordsToGenerate,
      ((channelsMask & 0x80) ? '1' : '0'),
      ((channelsMask & 0x40) ? '1' : '0'),
      ((channelsMask & 0x20) ? '1' : '0'),
      ((channelsMask & 0x10) ? '1' : '0'),
      ((channelsMask & 0x08) ? '1' : '0'),
      ((channelsMask & 0x04) ? '1' : '0'),
      ((channelsMask & 0x02) ? '1' : '0'),
      ((channelsMask & 0x01) ? '1' : '0'));
  }

  //tss_harv::creating chain
  IBaseFilter* const pRootFilter = this->_makeChain(
      new SensorInputGenerator(startTimestamp, channelsMask, nRecordsToGenerate,
        mediaType, useBigEndian,
        gapGenerator, //gaps generator
        signalLevel, noiseLevel,
        0.01f/*notifies progress each 1%*/,
        m_logger), //Sensor Input packets generator filter
      new PSFWriterFilter(volume, m_logger), //PSF write filter
      nullptr);
  return std::shared_ptr<IBaseFilter>(pRootFilter);
}

std::shared_ptr<IBaseFilter> GraphBuilder::buildSensorInputHaverstingChain(const IOperation* operation,
  const std::shared_ptr<PSFLibrary>& library,
  const sHarvestParams& params,
  const uint32_t maxQueueSize, 
  const std::shared_ptr<IClient>& client,
  const std::shared_ptr<IProgressDelegate>& progressDelegate) const
{
  __DEV_CALLSTACK_FUNC__;
  // restore volume
  std::shared_ptr<PSFVolume> const volume(library->findVolumeByID(PDB_eVolumeID::VOLUME_SENSOR_TIME_SERIES));
  if (volume == nullptr)
  {
    m_logger->error(__THIS_FUNC__, eErrorCategory::ERROR_CATEGORY_LIBRARY, eHarvLibErrorCode::HARVLIB_ERROR_VOLUME_NOT_FOUND, 
      "Failed to open 'VOLUME_SENSOR_TIME_SERIES' volume to harvest packets");
    return nullptr;
  }

  // create output path
  if (!this->_makePath(params.outputDir))
  {
    m_logger->error(__THIS_FUNC__, eErrorCategory::ERROR_CATEGORY_LIBRARY, eHarvLibErrorCode::HARVLIB_ERROR_OPERATION_FAILED,
      "Failed to create '%s' directory",
      params.outputDir.c_str());
    return nullptr;
  }

  //tss_harvlib::create array of filters
  std::vector<IBaseFilter*> filters;
  {
    //PSF reader filter (1 page preserved as MsgLog is designed to fit within 1 page)
    //2N + 1 - memory pool size for reader because consumer filter uses 2 N-sized queues (collecting queue + processing queue)
    const uint32_t nPagesPerPacketRecord = psf_utils::get_data_element_size_in_pages<MsgSensorInput::Header>();
    filters.push_back(new PSFReaderFilter(volume, params,
                                          (maxQueueSize << 1) + 1, nPagesPerPacketRecord, m_logger));
    //tss_harvlib::add MiniSEED write filter if path is specified, otherwise - print warning and skip filter
    if (!params.outputDir.empty())
    {
      filters.push_back(new MiniSEEDWriterFilter_SensorInput(library, params, maxQueueSize, m_logger));
    }
    else
    {
      m_logger->warning(__THIS_FUNC__, "Output directory was not specified! MiniSEED generation is DISABLED!");
    }
    //tss_harvlib::add progress filter
    filters.push_back(new ProgressFilter(operation, client, progressDelegate, m_logger));
  }

  //tss_harv::creating chain
  IBaseFilter* const pRootFilter = this->_makeChain(filters);
  return std::shared_ptr<IBaseFilter>(pRootFilter);
}


//----------------------------<SOH (Health input)>----------------------------
std::shared_ptr<IBaseFilter> GraphBuilder::buildHealthInputGenerationChain(const std::shared_ptr<PSFLibrary>& library,
  const timestamp_t startTimestamp, const uint32_t nPackets,
  const std::shared_ptr<IGapGenerator>& gapGenerator,
  const double signalLevel, const double noiseLevel) const
{
  __DEV_CALLSTACK_FUNC__;
  //tss_harv::restore volume from library
  std::shared_ptr<PSFVolume> const volume(library->findVolumeByID(PDB_eVolumeID::VOLUME_HEALTH_TIME_SERIES));
  if (volume == nullptr)
  {
    m_logger->error(__THIS_FUNC__, eErrorCategory::ERROR_CATEGORY_LIBRARY, eHarvLibErrorCode::HARVLIB_ERROR_VOLUME_NOT_FOUND,
      "Failed to find VOLUME_HEALTH_TIME_SERIES(id=%u) volume in library", (uint32_t)PDB_eVolumeID::VOLUME_HEALTH_TIME_SERIES);
    return nullptr;
  }

  uint32_t nRecordsToGenerate = nPackets;
  //tss_harv:: n=-1 means fill up completely
  if (nPackets == (uint32_t)-1)
  {
    const sPSFVolumeHeader_t* const pHeader = volume->getHeader();
    const uint32_t nRecordsPerSection = psf_utils::get_data_elements_per_section_max<MsgHealthInput::Header>();
    //tss_harvlib::records per volume = (nSections - 1(for volumes' header)) * records per section
    nRecordsToGenerate = (pHeader->sizeInChapters - 1) * nRecordsPerSection;
    m_logger->info(__THIS_FUNC__, "%u SOH packets will be generated to fill up the PSF volume entirely!",
      nRecordsToGenerate);
  }

  //tss_harv::creating chain
  IBaseFilter* const pRootFilter = this->_makeChain(
    new HealthInputGenerator(startTimestamp, nRecordsToGenerate,
      gapGenerator,
      signalLevel, noiseLevel,
      0.01f/*notifies progress each 1%*/,
      m_logger), //SOH packets generator filter
    new PSFWriterFilter(volume, m_logger), //PSF write filter
    nullptr);
  return std::shared_ptr<IBaseFilter>(pRootFilter);
}

std::shared_ptr<IBaseFilter> GraphBuilder::buildSohDataHaverstingChain(const IOperation* operation,
  const std::shared_ptr<PSFLibrary>& library,
  const sHarvestParams& params,
  const uint32_t channelsMask,
  const uint32_t maxQueueSize, 
  const std::shared_ptr<IClient>& client, 
  const std::shared_ptr<IProgressDelegate>& progressDelegate) const
{
  __DEV_CALLSTACK_FUNC__;
  // restore volume
  std::shared_ptr<PSFVolume> const volume(library->findVolumeByID(PDB_eVolumeID::VOLUME_HEALTH_TIME_SERIES));
  if (volume == nullptr)
  {
    m_logger->error(__THIS_FUNC__, eErrorCategory::ERROR_CATEGORY_LIBRARY, eHarvLibErrorCode::HARVLIB_ERROR_VOLUME_NOT_FOUND,
                    "Failed to open 'VOLUME_HEALTH_TIME_SERIES' volume to harvest packets");
    return nullptr;
  }
  
  // create output path
  if (!this->_makePath(params.outputDir))
  {
    m_logger->error(__THIS_FUNC__, eErrorCategory::ERROR_CATEGORY_LIBRARY, eHarvLibErrorCode::HARVLIB_ERROR_OPERATION_FAILED,
      "Failed to create '%s' directory",
      params.outputDir.c_str());
    return nullptr;
  }

  //tss_harvlib::create array of filters
  std::vector<IBaseFilter*> filters;
  {
    //PSF reader filter (1 page preserved as MsgLog is designed to fit within 1 page)
    //2N + 1 - memory pool size for reader because consumer filter uses 2 N-sized queues (collecting queue + processing queue)
    const uint32_t nPagesPerPacketRecord = psf_utils::get_data_element_size_in_pages<MsgHealthInput::Header>();
    filters.push_back(new PSFReaderFilter(volume, params,
                                          (maxQueueSize << 1) + 1, nPagesPerPacketRecord, m_logger));
    //tss_harvlib::add MiniSEED write filter if path is specified, otherwise - print warning and skip filter
    if (!params.outputDir.empty())
    {
      filters.push_back(new MiniSEEDWriterFilter_SohData(library, params, channelsMask, maxQueueSize, m_logger));
    }
    else
    {
      m_logger->warning(__THIS_FUNC__, "Output directory was not specified! SOH MiniSEED generation is DISABLED!");
    }
    //tss_harvlib::add progress filter
    filters.push_back(new ProgressFilter(operation, client, progressDelegate, m_logger));
  }
  
  //tss_harv::creating chain
  IBaseFilter* const pRootFilter = this->_makeChain(filters);
  return std::shared_ptr<IBaseFilter>(pRootFilter);
}


//------------------<SOH (ClockStatus)>---------------------------
std::shared_ptr<IBaseFilter> GraphBuilder::buildClockStatusGenerationChain(const std::shared_ptr<PSFLibrary>& library,
  const timestamp_t startTimestamp, const uint32_t nPackets,
  const std::shared_ptr<IGapGenerator>& gapGenerator) const
{
  __DEV_CALLSTACK_FUNC__;
  //tss_harv::restore volume from library
  std::shared_ptr<PSFVolume> const volume(library->findVolumeByID(PDB_eVolumeID::VOLUME_CLOCK_STATUS));
  if (volume == nullptr)
  {
    m_logger->error(__THIS_FUNC__, eErrorCategory::ERROR_CATEGORY_LIBRARY, eHarvLibErrorCode::HARVLIB_ERROR_VOLUME_NOT_FOUND,
      "Failed to find VOLUME_CLOCK_STATUS(id=%u) volume in library", (uint32_t)PDB_eVolumeID::VOLUME_CLOCK_STATUS);
    return nullptr;
  }

  uint32_t nRecordsToGenerate = nPackets;
  //tss_harv:: n=-1 means fill up completely
  if (nPackets == (uint32_t)-1)
  {
    const sPSFVolumeHeader_t* const pHeader = volume->getHeader();
    const uint32_t nRecordsPerSection = psf_utils::get_data_elements_per_section_max<MsgClockStatus::Header>();
    //tss_harvlib::records per volume = (nSections - 1(for volumes' header)) * records per section
    nRecordsToGenerate = (pHeader->sizeInChapters - 1) * nRecordsPerSection;
    m_logger->info(__THIS_FUNC__, "%u timing SOH (ClockStatus) packets will be generated to fill up the PSF volume entirely!",
      nRecordsToGenerate);
  }

  //tss_harv::creating chain
  IBaseFilter* const pRootFilter = this->_makeChain(
    new ClockStatusGenerator(startTimestamp, nRecordsToGenerate,
      gapGenerator,
      0.01f/*notifies progress each 1%*/,
      m_logger), //SOH packets generator filter
    new PSFWriterFilter(volume, m_logger), //PSF write filter
    nullptr);
  return std::shared_ptr<IBaseFilter>(pRootFilter);
}

std::shared_ptr<IBaseFilter> GraphBuilder::buildClockStatusHaverstingChain(const IOperation* operation,
  const std::shared_ptr<PSFLibrary>& library,
  const sHarvestParams& params,
  const uint32_t maxQueueSize,
  const std::shared_ptr<IClient>& client,
  const std::shared_ptr<IProgressDelegate>& progressDelegate) const
{
  __DEV_CALLSTACK_FUNC__;
  //tss_harv::restore volume
  std::shared_ptr<PSFVolume> const volume(library->findVolumeByID(PDB_eVolumeID::VOLUME_CLOCK_STATUS));
  if (volume == nullptr)
  {
    m_logger->error(__THIS_FUNC__, eErrorCategory::ERROR_CATEGORY_LIBRARY, eHarvLibErrorCode::HARVLIB_ERROR_VOLUME_NOT_FOUND,
      "Failed to open 'VOLUME_CLOCK_STATUS' volume to harvest packets");
    return nullptr;
  }

  // create output path
  if (!this->_makePath(params.outputDir))
  {
    m_logger->error(__THIS_FUNC__, eErrorCategory::ERROR_CATEGORY_LIBRARY, eHarvLibErrorCode::HARVLIB_ERROR_OPERATION_FAILED,
      "Failed to create '%s' directory",
      params.outputDir.c_str());
    return nullptr;
  }

  //tss_harvlib::create array of filters
  std::vector<IBaseFilter*> filters;
  {
    const uint32_t nPagesPerPacketRecord = psf_utils::get_data_element_size_in_pages<MsgClockStatus::Header>();
    filters.push_back(new PSFReaderFilter(volume, params,
                                          (maxQueueSize << 1) + 1, nPagesPerPacketRecord, m_logger));
    //tss_harvlib::add MiniSEED write filter if path is specified, otherwise - print warning and skip filter
    if (!params.outputDir.empty())
    {
      filters.push_back(new MiniSEEDWriterFilter_ClockStatus(library, params, maxQueueSize, m_logger));
    }
    else
    {
      m_logger->warning(__THIS_FUNC__, "Output directory was not specified! Timing SOH MiniSEED generation is DISABLED!");
    }
    //tss_harvlib::add progress filter
    filters.push_back(new ProgressFilter(operation, client, progressDelegate, m_logger));
  }

  //tss_harv::creating chain
  IBaseFilter* const pRootFilter = this->_makeChain(filters);
  return std::shared_ptr<IBaseFilter>(pRootFilter);
}

std::shared_ptr<IBaseFilter> GraphBuilder::buildDataProcessingChain(const IOperation* /*operation*/,
  const std::shared_ptr<PSFLibrary>& library,
  const uint32_t volumeId,
  const uint32_t maxQueueSize,
  const std::shared_ptr<IProcessorDelegate>& processorDelegate) const
{
  __DEV_CALLSTACK_FUNC__;
  // restore volume
  std::shared_ptr<PSFVolume> const volume(library->findVolumeByID(volumeId));
  if (volume == nullptr)
  {
    m_logger->error(__THIS_FUNC__, eErrorCategory::ERROR_CATEGORY_LIBRARY, eHarvLibErrorCode::HARVLIB_ERROR_VOLUME_NOT_FOUND,
      "Failed to open volume (id=%" PRIu32 ") to harvest packets", volumeId);
    return nullptr;
  }

  // default params (the entire volume). Revise later if time ranged reading is needed
  sHarvestParams params;
  params.lower.time = std::numeric_limits<timestamp_t>::min();
  params.upper.time = std::numeric_limits<timestamp_t>::max();
  // assume the worst case (the entire section per single data element)
  constexpr uint32_t nPagesPerElement = PSF_SECTIONS_to_PAGES(1u);
  // create array of filters
  const std::vector<IBaseFilter*> filters = {
    // PSF reader filter
    new PSFReaderFilter(volume, params, (maxQueueSize << 1) + 1, nPagesPerElement, m_logger),
    // add processor delegate filter
    new ProcessorDelegateFilter(maxQueueSize, processorDelegate, m_logger)
  };

  // create the chain
  IBaseFilter* const pRootFilter = this->_makeChain(filters);
  return std::shared_ptr<IBaseFilter>(pRootFilter);
}
